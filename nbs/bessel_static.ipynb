{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: JAX_PLATFORM_NAME=cpu\n",
      "The jaxtyping extension is already loaded. To reload it, use:\n",
      "  %reload_ext jaxtyping\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%env JAX_PLATFORM_NAME=cpu\n",
    "\n",
    "import jaxtyping  # noqa: F401\n",
    "\n",
    "%load_ext jaxtyping\n",
    "%jaxtyping.typechecker beartype.beartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jaxtyping import Float, Array\n",
    "\n",
    "from n3.architecture.controller import IdentityController, ControllerLike\n",
    "from n3.architecture.model import N3, ModelLike\n",
    "from n3.data import bessel\n",
    "from n3.utils.utils import grad_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2**15\n",
    "test_size = 0.2\n",
    "\n",
    "seed = 0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "N_max = 10  # per layer max number of neurons\n",
    "size_influence = 0.32\n",
    "epochs = 5_000\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = bessel.generate_data(\n",
    "    n_samples=n_samples,\n",
    "    test_size=test_size,\n",
    "    scaler=MinMaxScaler(feature_range=(-1, 1)),\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_train, y_train, \"k.\", alpha=0.5, label=f\"train:{len(x_train)}\")\n",
    "plt.plot(x_test, y_test, \"r.\", alpha=0.3, label=f\"test:{len(x_test)}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_base_loss(\n",
    "    model: ModelLike,\n",
    "    control: ControllerLike,\n",
    "    x: Float[Array, \"batch 1\"],\n",
    "    y: Float[Array, \"batch 1\"],\n",
    ") -> Float[Array, \"\"]:\n",
    "    pred = jax.vmap(model, in_axes=(0, None))(x, control)\n",
    "    return jnp.mean((pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_size_loss(controller: ControllerLike) -> Float[Array, \"\"]:\n",
    "    N = controller(jnp.ones((1,)))\n",
    "    return size_influence * jnp.mean((N - 1.0) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def make_step(\n",
    "    model: ModelLike,\n",
    "    controller: ControllerLike,\n",
    "    x: Float[Array, \"batch 1\"],\n",
    "    y: Float[Array, \"batch 1\"],\n",
    "    optim: optax.GradientTransformation,\n",
    "    opt_state: optax.OptState,\n",
    ") -> tuple[Float[Array, \"\"], ModelLike, ControllerLike, optax.OptState]:\n",
    "    loss_base, grads_base = eqx.filter_value_and_grad(compute_base_loss)(\n",
    "        model, controller, x, y\n",
    "    )\n",
    "    loss_size, grads_size = eqx.filter_value_and_grad(compute_size_loss)(controller)\n",
    "    loss = loss_base + loss_size\n",
    "\n",
    "    updates, opt_state = optim.update([grads_base, grads_size], opt_state)\n",
    "\n",
    "    model = eqx.apply_updates(model, updates[0])  # type: ignore\n",
    "    controller = eqx.apply_updates(controller, updates[1])  # type: ignore\n",
    "    return loss, model, controller, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def test_step(\n",
    "    model: ModelLike,\n",
    "    controller: ControllerLike,\n",
    "    x: Float[Array, \"batch 1\"],\n",
    "    y: Float[Array, \"batch 1\"],\n",
    ") -> Float[Array, \"\"]:\n",
    "    return compute_base_loss(model, controller, x, y) + compute_size_loss(controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key, control_key = jax.random.split(key)\n",
    "n3 = N3(1, 1, [N_max], model_key)\n",
    "control = IdentityController(1, control_key)\n",
    "\n",
    "optim = optax.adam(learning_rate=1e-3)\n",
    "opt_state = optim.init(eqx.filter([n3, control], eqx.is_inexact_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_list = []\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "controls2 = []\n",
    "base_grad_norms = []\n",
    "control_grad_norms = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, n3, control, opt_state = make_step(\n",
    "        n3, control, x_train, y_train, optim, opt_state\n",
    "    )\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        epoch_list.append(epoch)\n",
    "        test_loss = test_step(n3, control, x_test, y_test)\n",
    "\n",
    "        test_losses.append(test_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        controls2.append(control.params.item() ** 2)\n",
    "        control_grad_norms.append(\n",
    "            grad_norm(eqx.filter_grad(compute_size_loss)(control))\n",
    "        )\n",
    "        print(\n",
    "            f\"epoch: {epoch_list[-1]}, train_loss: {train_losses[-1]:.4e}, test_loss: {test_losses[-1]:.4e} control2: {controls2[-1]:.4e}\"\n",
    "        )\n",
    "        print(f\"Control_grad_norm: {control_grad_norms[-1]:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plotting train and test losses\n",
    "ax1.plot(epoch_list, train_losses, \"b.\", label=\"Train Loss\")\n",
    "ax1.plot(epoch_list, test_losses, \"r.\", label=\"Test Loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\", color=\"k\")\n",
    "ax1.set_yscale(\"log\")\n",
    "# ax1.set_xscale(\"log\")\n",
    "\n",
    "# Creating a second y-axis to plot control gradient norms\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(epoch_list, controls2, \"g.\", label=\"Control^2\")\n",
    "ax2.set_ylabel(\"Control^2\", color=\"g\")\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = jax.vmap(n3, in_axes=(0, None))(x_test, control)\n",
    "test_loss = jnp.mean((y_pred - y_test) ** 2)\n",
    "\n",
    "plt.plot(x_test, y_test, \"k.\", alpha=0.2, label=\"truth\")\n",
    "plt.plot(x_test, y_pred, \"r.\", alpha=0.2, label=f\"MSE: {test_loss: .4e}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
